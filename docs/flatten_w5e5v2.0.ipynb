{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "herbal-transport",
   "metadata": {},
   "source": [
    "# W5E5 download and postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-producer",
   "metadata": {},
   "source": [
    "- from: https://data.isimip.org/search/query/w5e5/climate_forcing/w5e5v2.0/climate_variable/pr/climate_variable/orog/climate_variable/tas/\n",
    "- download in terminal: `wget -i download_W5E5_script.txt` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heavy-tunnel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of glaciers: 216502 and number of W5E5 gridpoints with glaciers in them: 4713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14618/3570220549.py:45: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  mdf['Area'] = odf.groupby('unique_id').sum()['Area']\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from oggm import utils\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "path='/media/share/datasets/w5e5/'\n",
    "\n",
    "\n",
    "ds_inv = xr.open_dataset(path + 'orog_W5E5v2.0.nc')\n",
    "ds_inv = ds_inv.rename({'lat': 'latitude'})\n",
    "ds_inv = ds_inv.rename({'lon': 'longitude'})\n",
    "ds_inv.coords['longitude'] = np.where(ds_inv.longitude.values < 0,\n",
    "                                      ds_inv.longitude.values + 360,\n",
    "                                      ds_inv.longitude.values)\n",
    "# (ds.coords['longitude'] + 180) % 360 - 180\n",
    "ds_inv = ds_inv.sortby(ds_inv.latitude) # because it starts at 90 ... \n",
    "\n",
    "ds_inv = ds_inv.sortby(ds_inv.longitude)\n",
    "\n",
    "ds_inv.longitude.attrs['units'] = 'degrees_onlypositive'\n",
    "\n",
    "# get the dataset where coordinates of glaciers are stored\n",
    "frgi = utils.file_downloader('https://cluster.klima.uni-bremen.de/~oggm/rgi/rgi62_stats.h5')\n",
    "odf = pd.read_hdf(frgi, index_col=0)\n",
    "\n",
    "nx, ny = ds_inv.dims['longitude'], ds_inv.dims['latitude']\n",
    "# Nearest neighbor lookup\n",
    "cenlon_for_bins = np.where(odf['CenLon'] < -0.125,\n",
    "                           odf['CenLon']+360,\n",
    "                           odf['CenLon']) # just make them into 0-> 360 scheme\n",
    "lon_bins = np.linspace(0, 360, nx) # np.linspace(-0.125, 359.75+0.125, nx)\n",
    "# !!! attention W5E5 sorted from 90 to -90 !!!!\n",
    "#lat_bins = np.linspace(90, -90, ny)  #  \n",
    "#lat_bins = np.linspace(90+0.125, -90-0.125, ny)\n",
    "lat_bins = np.linspace(-90, +90, ny)\n",
    "odf['lon_id'] = np.digitize(cenlon_for_bins, lon_bins)-1\n",
    "odf['lat_id'] = np.digitize(odf['CenLat'], lat_bins)-1\n",
    "# Use unique grid points as index and compute the area per location\n",
    "odf['unique_id'] = ['{:03d}_{:03d}'.format(lon, lat) for (lon, lat) in zip(odf['lon_id'], odf['lat_id'])]\n",
    "mdf = odf.drop_duplicates(subset='unique_id').set_index('unique_id')\n",
    "mdf['Area'] = odf.groupby('unique_id').sum()['Area']\n",
    "print('Total number of glaciers: {} and number of W5E5 gridpoints with glaciers in them: {}'.format(len(odf), len(mdf)))\n",
    "\n",
    "# this is the mask that we need to remove all non-glacierized gridpoints\n",
    "mask = np.full((ny, nx), np.NaN)\n",
    "mask[mdf['lat_id'], mdf['lon_id']] = 1#mdf['Area']\n",
    "ds_inv['glacier_mask'] = (('latitude', 'longitude'), np.isfinite(mask))\n",
    "\n",
    "#c = (ds_inv.longitude - lon)**2 + (ds_inv.latitude - lat)**2\n",
    "lon, lat = (10.7584, 46.8003)\n",
    "surf_hef = ds_inv.sel(longitude=lon, latitude = lat, method='nearest')\n",
    "np.testing.assert_allclose(surf_hef.orog.values, 2250, rtol=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from oggm import utils\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "path='/home/www/lschuster/W5E5'\n",
    "\n",
    "\n",
    "ds_inv = xr.open_dataset('orog_W5E5v2.0.nc')\n",
    "#ds_inv = xr.open_dataset('/home/users/lschuster/glacierMIP/ASurf_WFDE5_CRU_v1.1.nc')\n",
    "ds_inv = ds_inv.rename({'lat': 'latitude'})\n",
    "ds_inv = ds_inv.rename({'lon': 'longitude'})\n",
    "ds_inv.coords['longitude'] = np.where(ds_inv.longitude.values < 0,\n",
    "                                      ds_inv.longitude.values + 360,\n",
    "                                      ds_inv.longitude.values)\n",
    "# (ds.coords['longitude'] + 180) % 360 - 180\n",
    "ds_inv = ds_inv.sortby(ds_inv.latitude) # because it starts at 90 ... \n",
    "\n",
    "ds_inv = ds_inv.sortby(ds_inv.longitude)\n",
    "\n",
    "ds_inv.longitude.attrs['units'] = 'degrees_onlypositive'\n",
    "\n",
    "# get the dataset where coordinates of glaciers are stored\n",
    "frgi = utils.file_downloader('https://cluster.klima.uni-bremen.de/~oggm/rgi/rgi62_stats.h5')\n",
    "odf = pd.read_hdf(frgi, index_col=0)\n",
    "\n",
    "nx, ny = ds_inv.dims['longitude'], ds_inv.dims['latitude']\n",
    "# Nearest neighbor lookup\n",
    "cenlon_for_bins = np.where(odf['CenLon'] < -0.125,\n",
    "                           odf['CenLon']+360,\n",
    "                           odf['CenLon']) # just make them into 0-> 360 scheme\n",
    "lon_bins = np.linspace(0, 360, nx) # np.linspace(-0.125, 359.75+0.125, nx)\n",
    "# !!! attention W5E5 sorted from 90 to -90 !!!!\n",
    "#lat_bins = np.linspace(90, -90, ny)  #  \n",
    "#lat_bins = np.linspace(90+0.125, -90-0.125, ny)\n",
    "lat_bins = np.linspace(-90, +90, ny)\n",
    "odf['lon_id'] = np.digitize(cenlon_for_bins, lon_bins)-1\n",
    "odf['lat_id'] = np.digitize(odf['CenLat'], lat_bins)-1\n",
    "# Use unique grid points as index and compute the area per location\n",
    "odf['unique_id'] = ['{:03d}_{:03d}'.format(lon, lat) for (lon, lat) in zip(odf['lon_id'], odf['lat_id'])]\n",
    "mdf = odf.drop_duplicates(subset='unique_id').set_index('unique_id')\n",
    "mdf['Area'] = odf.groupby('unique_id').sum()['Area']\n",
    "print('Total number of glaciers: {} and number of W5E5 gridpoints with glaciers in them: {}'.format(len(odf), len(mdf)))\n",
    "\n",
    "# this is the mask that we need to remove all non-glacierized gridpoints\n",
    "mask = np.full((ny, nx), np.NaN)\n",
    "mask[mdf['lat_id'], mdf['lon_id']] = 1#mdf['Area']\n",
    "ds_inv['glacier_mask'] = (('latitude', 'longitude'), np.isfinite(mask))\n",
    "\n",
    "#c = (ds_inv.longitude - lon)**2 + (ds_inv.latitude - lat)**2\n",
    "lon, lat = (10.7584, 46.8003)\n",
    "surf_hef = ds_inv.sel(longitude=lon, latitude = lat, method='nearest')\n",
    "np.testing.assert_allclose(surf_hef.orog.values, 2250, rtol=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_inv_wfde5 = xr.open_dataset('/home/users/lschuster/ASurf_WFDE5_CRU_v1.1.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-cameroon",
   "metadata": {},
   "source": [
    "## yearly and monthly (actually both together ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "make_daily = False\n",
    "if make_daily:\n",
    "    \n",
    "    try:\n",
    "        os.mkdir('/home/users/lschuster/W5E5/flattened')\n",
    "        os.mkdir('/home/users/lschuster/W5E5/flattened/tmp_pr')\n",
    "        os.mkdir('/home/users/lschuster/W5E5/flattened/tmp_tas')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    yss = [1979, 1981, 1991, 2001, 2011]\n",
    "    yee = [1980, 1990, 2000, 2010, 2019]\n",
    "    for var in ['pr', 'tas']:\n",
    "        for ys, ye in zip(yss, yee):\n",
    "            ds = xr.open_dataset('{}_W5E5v2.0_{}0101-{}1231.nc'.format(var, ys, ye))\n",
    "\n",
    "            ds = ds.rename({'lon':'longitude'}).rename({'lat':'latitude'})\n",
    "            ds.coords['longitude'] = np.where(ds.longitude.values < 0,\n",
    "                                              ds.longitude.values + 360,\n",
    "                                              ds.longitude.values)\n",
    "\n",
    "            ds = ds.sortby(ds.longitude)\n",
    "            ds.longitude.attrs['units'] = 'degrees_onlypositive'\n",
    "\n",
    "            # this takes too long !!!\n",
    "            # ds_merged_glaciers = xr_prcp.where(ds_inv['glacier_mask'], drop = True)\n",
    "\n",
    "            ds['ASurf'] = ds_inv['orog'] #ds_inv['ASurf']\n",
    "            if ys==1979 and var =='pr':\n",
    "\n",
    "                # as we use here only those gridpoints where glaciers are involved, need to put the mask on dsi as well!\n",
    "                # dsi = ds_inv.where(ds_inv['glacier_mask'], drop = True)  # this makes out of in total 6483600 points only 116280 points!!!\n",
    "                dsi = ds.isel(time=[0]).where(ds_inv['glacier_mask'], drop = True)\n",
    "                # we do not want any dependency on latitude and longitude\n",
    "                dsif = dsi.stack(points=('latitude', 'longitude')).reset_index(('points'))\n",
    "                #dsif # so far still many points \n",
    "\n",
    "                # drop the non-glacierized points\n",
    "                dsifs = dsif.where(np.isfinite(dsi[var].stack(points=('latitude',\n",
    "                                                                      'longitude')).reset_index(('time',\n",
    "                                                                                                 'points'))), drop=True)\n",
    "                # I have to drop the 'time_' dimension, to be equal to the era5_land example, because the invariant file should not have any time dependence !\n",
    "                dsifs = dsifs.drop_vars(var)\n",
    "                dsifs = dsifs.drop('time')\n",
    "                dsifs = dsifs.drop('time_')\n",
    "                dsifs.to_netcdf('/home/users/lschuster/W5E5/flattened/w5e5v2.0_glacier_invariant_flat.nc')\n",
    "\n",
    "                #check if gridpoint nearest to hef is right!!!\n",
    "                # happened once that something went wrong here ...\n",
    "                lon, lat = (10.7584, 46.8003)\n",
    "                #orog = xr.open_dataset('/home/lilianschuster/Downloads/w5e5v2.0_glacier_invariant_flat.nc').ASurf\n",
    "                orog = dsifs.ASurf\n",
    "                c = (orog.longitude - lon)**2 + (orog.latitude - lat)**2\n",
    "                surf_hef = orog.isel(points=c.argmin())\n",
    "                np.testing.assert_allclose(surf_hef, 2250, rtol=0.1)\n",
    "            ds = ds.drop_vars('ASurf')\n",
    "\n",
    "            for t in ds.time.values[:]:  # ds_merged_glaciers.time.values: .sel(time=slice('1901-04','2016-12'))\n",
    "                # produce a temporary file for each month\n",
    "                sel_l = ds.sel(time=[t])\n",
    "                # don't do the dropping twice!!!!\n",
    "                #sel = sel_l.where(ds_inv['glacier_mask'], drop = True)\n",
    "                sel = sel_l.where(ds_inv['glacier_mask'])\n",
    "                sel = sel.stack(points=('latitude', 'longitude')).reset_index(('time', 'points'))\n",
    "                sel = sel.where(np.isfinite(sel[var]), drop=True)\n",
    "                sel.to_netcdf('/home/users/lschuster/W5E5/flattened/tmp_{}/tmp_{}.nc'.format(var, str(t)[:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7cfc47f-fd43-48a0-9dcc-bc5fc2ac247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (time: 366, points: 4713)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1980-01-01 1980-01-02 ... 1980-12-31\n",
      "    latitude   (points) float64 dask.array<chunksize=(4713,), meta=np.ndarray>\n",
      "    longitude  (points) float64 dask.array<chunksize=(4713,), meta=np.ndarray>\n",
      "Dimensions without coordinates: points\n",
      "Data variables:\n",
      "    pr         (time, points) float32 dask.array<chunksize=(1, 4713), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:  CF-1.7\n",
      "    title:        WFDE5 over land merged with ERA5 over the ocean (W5E5) vers...\n",
      "    institution:  Potsdam Institute for Climate Impact Research (PIK)\n",
      "    project:      Inter-Sectoral Impact Model Intercomparison Project phase 3...\n",
      "    contact:      ISIMIP cross-sectoral science team <info@isimip.org> <https...\n",
      "    summary:      WFDE5 (with GPCC precipitation correction) over land merged...\n",
      "    references:   Cucchi et al. (2020) <https://doi.org/10.5194/essd-12-2097-...\n",
      "    version:      2.0\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: b'/home/users/lschuster/W5E5/flattened/tmp_pr/tmp2_1980.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/packages/mambaforge/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/file_manager.py:209\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/packages/mambaforge/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/lru_cache.py:55\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 55\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/home/users/lschuster/W5E5/flattened/tmp_pr/tmp2_1980.nc',), 'a', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), 'b2a4dfca-6fe6-45da-99d7-f567abecc7c4']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dso_y \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_mfdataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/bsurya/work/oggm/AIR-suitability-index/MBsandbox/flattened/tmp_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/tmp_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-*.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(var, \u001b[38;5;28mstr\u001b[39m(y)),\n\u001b[1;32m      7\u001b[0m                                   concat_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, combine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnested\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# .rename_vars({'time_':'time'})\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(dso_y)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdso_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/users/lschuster/W5E5/flattened/tmp_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/tmp2_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m dso_y\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/packages/mambaforge/envs/oggm_env/lib/python3.9/site-packages/xarray/core/dataset.py:1904\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1901\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1902\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 1904\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[1;32m   1905\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/packages/mambaforge/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/api.py:1214\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1212\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized option \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid_netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m         )\n\u001b[0;32m-> 1214\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43mstore_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unlimited_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1217\u001b[0m     unlimited_dims \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mencoding\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlimited_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/packages/mambaforge/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:376\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    370\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    371\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    373\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    374\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    375\u001b[0m )\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/packages/mambaforge/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:323\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/packages/mambaforge/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:385\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/packages/mambaforge/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:379\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    380\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/packages/mambaforge/envs/oggm_env/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/packages/mambaforge/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/file_manager.py:197\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/packages/mambaforge/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/file_manager.py:215\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    213\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    214\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 215\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: b'/home/users/lschuster/W5E5/flattened/tmp_pr/tmp2_1980.nc'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "# make yearly files\n",
    "var = 'pr'\n",
    "y = 1980\n",
    "dso_y = xr.open_mfdataset('/home/bsurya/work/oggm/AIR-suitability-index/MBsandbox/flattened/tmp_{}/tmp_{}-*.nc'.format(var, str(y)),\n",
    "                                  concat_dim='time', combine='nested') # .rename_vars({'time_':'time'})\n",
    "print(dso_y)\n",
    "dso_y.to_netcdf('/home/users/lschuster/W5E5/flattened/tmp_{}/tmp2_{}.nc'.format(var, str(y)))\n",
    "dso_y.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stretch-namibia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr 1979\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (time: 31, points: 4713)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1979-01-01 1979-01-02 ... 1979-01-31\n",
      "    latitude   (points) float64 dask.array<chunksize=(4713,), meta=np.ndarray>\n",
      "    longitude  (points) float64 dask.array<chunksize=(4713,), meta=np.ndarray>\n",
      "Dimensions without coordinates: points\n",
      "Data variables:\n",
      "    pr         (time, points) float32 dask.array<chunksize=(1, 4713), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:  CF-1.7\n",
      "    title:        WFDE5 over land merged with ERA5 over the ocean (W5E5) vers...\n",
      "    institution:  Potsdam Institute for Climate Impact Research (PIK)\n",
      "    project:      Inter-Sectoral Impact Model Intercomparison Project phase 3...\n",
      "    contact:      ISIMIP cross-sectoral science team <info@isimip.org> <https...\n",
      "    summary:      WFDE5 (with GPCC precipitation correction) over land merged...\n",
      "    references:   Cucchi et al. (2020) <https://doi.org/10.5194/essd-12-2097-...\n",
      "    version:      2.0\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: b'/home/users/lschuster/W5E5/flattened/tmp_pr/tmp2_1979.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/packages/anaconda3/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/file_manager.py:209\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/packages/anaconda3/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/lru_cache.py:55\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 55\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/home/users/lschuster/W5E5/flattened/tmp_pr/tmp2_1979.nc',), 'a', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), 'ff996da9-e86d-46d0-98bb-b4d88ad17650']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m         dso_y \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_mfdataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/bsurya/work/oggm/AIR-suitability-index/MBsandbox/flattened/tmp_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/tmp_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-01-*.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(var, \u001b[38;5;28mstr\u001b[39m(y)),\n\u001b[1;32m      8\u001b[0m                                   concat_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, combine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnested\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# .rename_vars({'time_':'time'})\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(dso_y)\n\u001b[0;32m---> 10\u001b[0m         \u001b[43mdso_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/users/lschuster/W5E5/flattened/tmp_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/tmp2_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         dso_y\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# aggregate yearly files\u001b[39;00m\n",
      "File \u001b[0;32m~/packages/anaconda3/envs/oggm_env/lib/python3.9/site-packages/xarray/core/dataset.py:1903\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1900\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1901\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 1903\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[1;32m   1904\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/packages/anaconda3/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/api.py:1213\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1210\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized option \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid_netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1212\u001b[0m         )\n\u001b[0;32m-> 1213\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43mstore_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unlimited_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     unlimited_dims \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mencoding\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlimited_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/packages/anaconda3/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:376\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    370\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    371\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    373\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    374\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    375\u001b[0m )\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/packages/anaconda3/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:323\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/packages/anaconda3/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:385\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/packages/anaconda3/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/netCDF4_.py:379\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    380\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/packages/anaconda3/envs/oggm_env/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/packages/anaconda3/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/file_manager.py:197\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/packages/anaconda3/envs/oggm_env/lib/python3.9/site-packages/xarray/backends/file_manager.py:215\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    213\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    214\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 215\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: b'/home/users/lschuster/W5E5/flattened/tmp_pr/tmp2_1979.nc'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "# make yearly files\n",
    "for var in ['pr']:\n",
    "    for y in np.arange(1979, 2020):\n",
    "        print(var,y)\n",
    "        dso_y = xr.open_mfdataset('/home/bsurya/work/oggm/AIR-suitability-index/MBsandbox/flattened/tmp_{}/tmp_{}-01-*.nc'.format(var, str(y)),\n",
    "                                  concat_dim='time', combine='nested') # .rename_vars({'time_':'time'})\n",
    "        print(dso_y)\n",
    "        dso_y.to_netcdf('/home/users/lschuster/W5E5/flattened/tmp_{}/tmp2_{}.nc'.format(var, str(y)))\n",
    "        dso_y.close()\n",
    "    \n",
    "# aggregate yearly files\n",
    "for var in ['pr', 'tas']:\n",
    "    dso_all2 = xr.open_mfdataset('/home/users/lschuster/W5E5/flattened/tmp_{}/tmp2_*.nc'.format(var),\n",
    "                        concat_dim='time', combine='nested', parallel = True).rename_vars({'time_':'time'})\n",
    "    \n",
    "    dso_all2.attrs['history'] = 'longitudes to 0 -> 360,  only glacier gridpoints chosen and flattened latitude/longitude --> points'\n",
    "    dso_all2.attrs['postprocessing_date'] = str(np.datetime64('today','D'))\n",
    "    dso_all2.attrs['postprocessing_scientist'] = 'lilian.schuster@student.uibk.ac.at'\n",
    "    dso_all2.to_netcdf('/home/users/lschuster/W5E5/flattened/w5e5v2.0_{}_global_daily_flat_glaciers_1979_2019.nc'.format(var))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make monthly files \n",
    "for var in ['pr', 'tas']:\n",
    "\n",
    "    pathi= 'flattened/w5e5v2.0_{}_global_daily_flat_glaciers_1979_2019.nc'.format(var)\n",
    "    ds = xr.open_dataset(pathi)\n",
    "\n",
    "\n",
    "    ds_monthly = ds.resample(time='MS', keep_attrs=True).mean(keep_attrs=True)\n",
    "\n",
    "    ds_monthly.attrs['postprocessing_scientist'] = 'lilian.schuster@student.uibk.ac.at'\n",
    "    ds_monthly.attrs['postprocessing_actions'] =  (\"using xarray: ds_monthly = ds.resample(time='MS', keep_attrs=True).mean(keep_attrs=True)\\n\"\n",
    "                                                                      \"ds_monthly.to_netcdf()\\n\")\n",
    "\n",
    "    ds_monthly.to_netcdf('flattened/w5e5v2.0_{}_global_monthly_flat_glaciers_1979_2019.nc'.format(var))\n",
    "    \n",
    "    if var == 'tas':\n",
    "        # also compute monthly daily std:\n",
    "\n",
    "        ds_tas_daily_std = ds.resample(time='MS', keep_attrs=True).std(keep_attrs=True)\n",
    "        ds_tas_daily_std = ds_tas_daily_std.rename_vars(dict(tas='tas_std'))\n",
    "        # now have to change variable tas to tas_std and its attributes \n",
    "        ds_tas_daily_std.tas_std.attrs['standard_name'] = 'air_temperature_daily_std'\n",
    "        ds_tas_daily_std.tas_std.attrs['long_name'] = 'Near-Surface Air Temperature daily standard deviation'\n",
    "        ds_tas_daily_std.attrs['postprocessing_date'] = str(np.datetime64('today','D'))\n",
    "        ds_tas_daily_std.attrs['postprocessing_scientist'] = 'lilian.schuster@student.uibk.ac.at'\n",
    "        ds_tas_daily_std.attrs['postprocessing_actions'] =  (\"using xarray: \\n\"\n",
    "                                                                      \"ds_tas_daily_std = ds.resample(time='MS', keep_attrs=True).std(keep_attrs=True)\\n\"\n",
    "                                                                       \"ds_tas_daily_std = ds_tas_daily_std.rename_vars(dict(tas='tas_std'))\\n\"\n",
    "                                                                       \"ds_tas_daily_std.tas_std.attrs['standard_name'] = 'air_temperature_daily_std'\\n\"\n",
    "                                                                       \"ds_tas_daily_std.tas_std.attrs['long_name'] = 'Near-Surface Air Temperature daily standard deviation'\\n\"\n",
    "                                                                      \"ds_tas_daily_std.to_netcdf(...)\\n\")\n",
    "        \n",
    "        ds_tas_daily_std.to_netcdf('flattened/w5e5v2.0_tas_std_global_monthly_flat_glaciers_1979_2019.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.remove('/home/users/lschuster/glacierMIP/isimip3b/flattened/tmp_monthly_{}/'.format(var))\n",
    "import glob\n",
    "for var in ['pr', 'tas']:\n",
    "    files = glob.glob('/home/users/lschuster/W5E5/flattened/tmp_{}/tmp*'.format(var))\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = xr.open_dataset('flattened/w5e5v2.0_pr_global_daily_flat_glaciers_1979_2019.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas = xr.open_dataset('flattened/w5e5v2.0_tas_global_daily_flat_glaciers_1979_2019.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon, lat = (10.7584, 46.8003)\n",
    "inv = xr.open_dataset('flattened/w5e5v2.0_glacier_invariant_flat.nc').ASurf\n",
    "c = (inv.longitude - lon)**2 + (inv.latitude - lat)**2\n",
    "tas_sel = tas.isel(points=c.argmin())\n",
    "pr_sel = pr.isel(points=c.argmin())\n",
    "\n",
    "tas_sel.tas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pr_sel.pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_sel.tas.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tas_sel.tas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-librarian",
   "metadata": {},
   "source": [
    "**move the files somewhere where everyone can get them**\n",
    "- `mkdir /home/www/lschuster/w5e5v2.0`\n",
    "- `mkdir /home/www/lschuster/w5e5v2.0/flattened`\n",
    "- `mkdir /home/www/lschuster/w5e5v2.0/flattened/monthly`\n",
    "- `mkdir /home/www/lschuster/w5e5v2.0/flattened/daily`\n",
    "- `cp flattened/w5e5*monthly* /home/www/lschuster/w5e5v2.0/flattened/monthly/`\n",
    "- `cp flattened/w5e5*daily* /home/www/lschuster/w5e5v2.0/flattened/daily/`\n",
    "- `cp flattened/w5e5*inv* /home/www/lschuster/w5e5v2.0/flattened/daily/`\n",
    "- `cp flattened/w5e5*inv* /home/www/lschuster/w5e5v2.0/flattened/monthly/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-baking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
